{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I strongly recommend to go through the article [here](https://www.analyticsvidhya.com/blog/2019/07/learn-build-first-speech-to-text-model-python/) to understand the basics of signal processing prior implementing the speech to text.\n",
    "\n",
    "**Understanding the Problem Statement for our Speech-to-Text Project**\n",
    "\n",
    "Let’s understand the problem statement of our project before we move into the implementation part.\n",
    "\n",
    "We might be on the verge of having too many screens around us. It seems like every day, new versions of common objects are “re-invented” with built-in wifi and bright touchscreens. A promising antidote to our screen addiction is voice interfaces. \n",
    "\n",
    "TensorFlow recently released the Speech Commands Datasets. It includes 65,000 one-second long utterances of 30 short words, by thousands of different people. We’ll build a speech recognition system that understands simple spoken commands.\n",
    "\n",
    "You can download the dataset from [here](https://www.kaggle.com/c/tensorflow-speech-recognition-challenge).\n",
    "\n",
    "**Implementing the Speech-to-Text Model in Python**\n",
    "\n",
    "The wait is over! It’s time to build our own Speech-to-Text model from scratch.\n",
    "\n",
    "**Import the libraries**\n",
    "\n",
    "First, import all the necessary libraries into our notebook. LibROSA and SciPy are the Python libraries used for processing audio signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'librosa'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-12ed7d3f6767>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mipd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'librosa'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rock\n",
      "['rock.00011.wav', 'rock.00005.wav', 'rock.00039.wav', 'rock.00038.wav', 'rock.00004.wav', 'rock.00010.wav', 'rock.00006.wav', 'rock.00012.wav', 'rock.00013.wav', 'rock.00007.wav', 'rock.00003.wav', 'rock.00017.wav', 'rock.00016.wav', 'rock.00002.wav', 'rock.00028.wav', 'rock.00014.wav', 'rock.00000.wav', 'rock.00001.wav', 'rock.00015.wav', 'rock.00029.wav', 'rock.00099.wav', 'rock.00072.wav', 'rock.00066.wav', 'rock.00067.wav', 'rock.00073.wav', 'rock.00098.wav', 'rock.00065.wav', 'rock.00071.wav', 'rock.00059.wav', 'rock.00058.wav', 'rock.00070.wav', 'rock.00064.wav', 'rock.00048.wav', 'rock.00060.wav', 'rock.00074.wav', 'rock.00075.wav', 'rock.00061.wav', 'rock.00049.wav', 'rock.00088.wav', 'rock.00077.wav', 'rock.00063.wav', 'rock.00062.wav', 'rock.00076.wav', 'rock.00089.wav', 'rock.00090.wav', 'rock.00084.wav', 'rock.00053.wav', 'rock.00047.wav', 'rock.00046.wav', 'rock.00052.wav', 'rock.00085.wav', 'rock.00091.wav', 'rock.00087.wav', 'rock.00093.wav', 'rock.00044.wav', 'rock.00050.wav', 'rock.00078.wav', 'rock.00079.wav', 'rock.00051.wav', 'rock.00045.wav', 'rock.00092.wav', 'rock.00086.wav', 'rock.00082.wav', 'rock.00096.wav', 'rock.00069.wav', 'rock.00041.wav', 'rock.00055.wav', 'rock.00054.wav', 'rock.00040.wav', 'rock.00068.wav', 'rock.00097.wav', 'rock.00083.wav', 'rock.00095.wav', 'rock.00081.wav', 'rock.00056.wav', 'rock.00042.wav', 'rock.00043.wav', 'rock.00057.wav', 'rock.00080.wav', 'rock.00094.wav', 'rock.00030.wav', 'rock.00024.wav', 'rock.00018.wav', 'rock.00019.wav', 'rock.00025.wav', 'rock.00031.wav', 'rock.00027.wav', 'rock.00033.wav', 'rock.00032.wav', 'rock.00026.wav', 'rock.00022.wav', 'rock.00036.wav', 'rock.00037.wav', 'rock.00023.wav', 'rock.00009.wav', 'rock.00035.wav', 'rock.00021.wav', 'rock.00020.wav', 'rock.00034.wav', 'rock.00008.wav']\n",
      "blues\n",
      "['blues.00093.wav', 'blues.00087.wav', 'blues.00050.wav', 'blues.00044.wav', 'blues.00078.wav', 'blues.00079.wav', 'blues.00045.wav', 'blues.00051.wav', 'blues.00086.wav', 'blues.00092.wav', 'blues.00084.wav', 'blues.00090.wav', 'blues.00047.wav', 'blues.00053.wav', 'blues.00052.wav', 'blues.00046.wav', 'blues.00091.wav', 'blues.00085.wav', 'blues.00081.wav', 'blues.00095.wav', 'blues.00042.wav', 'blues.00056.wav', 'blues.00057.wav', 'blues.00043.wav', 'blues.00094.wav', 'blues.00080.wav', 'blues.00096.wav', 'blues.00082.wav', 'blues.00069.wav', 'blues.00055.wav', 'blues.00041.wav', 'blues.00040.wav', 'blues.00054.wav', 'blues.00068.wav', 'blues.00083.wav', 'blues.00097.wav', 'blues.00033.wav', 'blues.00027.wav', 'blues.00026.wav', 'blues.00032.wav', 'blues.00024.wav', 'blues.00030.wav', 'blues.00018.wav', 'blues.00019.wav', 'blues.00031.wav', 'blues.00025.wav', 'blues.00009.wav', 'blues.00021.wav', 'blues.00035.wav', 'blues.00034.wav', 'blues.00020.wav', 'blues.00008.wav', 'blues.00036.wav', 'blues.00022.wav', 'blues.00023.wav', 'blues.00037.wav', 'blues.00012.wav', 'blues.00006.wav', 'blues.00007.wav', 'blues.00013.wav', 'blues.00005.wav', 'blues.00011.wav', 'blues.00039.wav', 'blues.00038.wav', 'blues.00010.wav', 'blues.00004.wav', 'blues.00028.wav', 'blues.00000.wav', 'blues.00014.wav', 'blues.00015.wav', 'blues.00001.wav', 'blues.00029.wav', 'blues.00017.wav', 'blues.00003.wav', 'blues.00002.wav', 'blues.00016.wav', 'blues.00071.wav', 'blues.00065.wav', 'blues.00059.wav', 'blues.00058.wav', 'blues.00064.wav', 'blues.00070.wav', 'blues.00099.wav', 'blues.00066.wav', 'blues.00072.wav', 'blues.00073.wav', 'blues.00067.wav', 'blues.00098.wav', 'blues.00088.wav', 'blues.00063.wav', 'blues.00077.wav', 'blues.00076.wav', 'blues.00062.wav', 'blues.00089.wav', 'blues.00048.wav', 'blues.00074.wav', 'blues.00060.wav', 'blues.00061.wav', 'blues.00075.wav', 'blues.00049.wav']\n",
      "metal\n",
      "['metal.00022.wav', 'metal.00036.wav', 'metal.00037.wav', 'metal.00023.wav', 'metal.00009.wav', 'metal.00035.wav', 'metal.00021.wav', 'metal.00020.wav', 'metal.00034.wav', 'metal.00008.wav', 'metal.00030.wav', 'metal.00024.wav', 'metal.00018.wav', 'metal.00019.wav', 'metal.00025.wav', 'metal.00031.wav', 'metal.00027.wav', 'metal.00033.wav', 'metal.00032.wav', 'metal.00026.wav', 'metal.00082.wav', 'metal.00096.wav', 'metal.00069.wav', 'metal.00041.wav', 'metal.00055.wav', 'metal.00054.wav', 'metal.00040.wav', 'metal.00068.wav', 'metal.00097.wav', 'metal.00083.wav', 'metal.00095.wav', 'metal.00081.wav', 'metal.00056.wav', 'metal.00042.wav', 'metal.00043.wav', 'metal.00057.wav', 'metal.00080.wav', 'metal.00094.wav', 'metal.00090.wav', 'metal.00084.wav', 'metal.00053.wav', 'metal.00047.wav', 'metal.00046.wav', 'metal.00052.wav', 'metal.00085.wav', 'metal.00091.wav', 'metal.00087.wav', 'metal.00093.wav', 'metal.00044.wav', 'metal.00050.wav', 'metal.00078.wav', 'metal.00079.wav', 'metal.00051.wav', 'metal.00045.wav', 'metal.00092.wav', 'metal.00086.wav', 'metal.00048.wav', 'metal.00060.wav', 'metal.00074.wav', 'metal.00075.wav', 'metal.00061.wav', 'metal.00049.wav', 'metal.00088.wav', 'metal.00077.wav', 'metal.00063.wav', 'metal.00062.wav', 'metal.00076.wav', 'metal.00089.wav', 'metal.00099.wav', 'metal.00072.wav', 'metal.00066.wav', 'metal.00067.wav', 'metal.00073.wav', 'metal.00098.wav', 'metal.00065.wav', 'metal.00071.wav', 'metal.00059.wav', 'metal.00058.wav', 'metal.00070.wav', 'metal.00064.wav', 'metal.00003.wav', 'metal.00017.wav', 'metal.00016.wav', 'metal.00002.wav', 'metal.00028.wav', 'metal.00014.wav', 'metal.00000.wav', 'metal.00001.wav', 'metal.00015.wav', 'metal.00029.wav', 'metal.00011.wav', 'metal.00005.wav', 'metal.00039.wav', 'metal.00038.wav', 'metal.00004.wav', 'metal.00010.wav', 'metal.00006.wav', 'metal.00012.wav', 'metal.00013.wav', 'metal.00007.wav']\n",
      "pop\n",
      "['pop.00027.wav', 'pop.00033.wav', 'pop.00032.wav', 'pop.00026.wav', 'pop.00030.wav', 'pop.00024.wav', 'pop.00018.wav', 'pop.00019.wav', 'pop.00025.wav', 'pop.00031.wav', 'pop.00009.wav', 'pop.00035.wav', 'pop.00021.wav', 'pop.00020.wav', 'pop.00034.wav', 'pop.00008.wav', 'pop.00022.wav', 'pop.00036.wav', 'pop.00037.wav', 'pop.00023.wav', 'pop.00044.wav', 'pop.00050.wav', 'pop.00078.wav', 'pop.00087.wav', 'pop.00093.wav', 'pop.00092.wav', 'pop.00086.wav', 'pop.00079.wav', 'pop.00051.wav', 'pop.00045.wav', 'pop.00053.wav', 'pop.00047.wav', 'pop.00090.wav', 'pop.00084.wav', 'pop.00085.wav', 'pop.00091.wav', 'pop.00046.wav', 'pop.00052.wav', 'pop.00056.wav', 'pop.00042.wav', 'pop.00095.wav', 'pop.00081.wav', 'pop.00080.wav', 'pop.00094.wav', 'pop.00043.wav', 'pop.00057.wav', 'pop.00069.wav', 'pop.00041.wav', 'pop.00055.wav', 'pop.00082.wav', 'pop.00096.wav', 'pop.00097.wav', 'pop.00083.wav', 'pop.00054.wav', 'pop.00040.wav', 'pop.00068.wav', 'pop.00065.wav', 'pop.00071.wav', 'pop.00059.wav', 'pop.00058.wav', 'pop.00070.wav', 'pop.00064.wav', 'pop.00072.wav', 'pop.00066.wav', 'pop.00099.wav', 'pop.00098.wav', 'pop.00067.wav', 'pop.00073.wav', 'pop.00077.wav', 'pop.00063.wav', 'pop.00088.wav', 'pop.00089.wav', 'pop.00062.wav', 'pop.00076.wav', 'pop.00048.wav', 'pop.00060.wav', 'pop.00074.wav', 'pop.00075.wav', 'pop.00061.wav', 'pop.00049.wav', 'pop.00006.wav', 'pop.00012.wav', 'pop.00013.wav', 'pop.00007.wav', 'pop.00011.wav', 'pop.00005.wav', 'pop.00039.wav', 'pop.00038.wav', 'pop.00004.wav', 'pop.00010.wav', 'pop.00028.wav', 'pop.00014.wav', 'pop.00000.wav', 'pop.00001.wav', 'pop.00015.wav', 'pop.00029.wav', 'pop.00003.wav', 'pop.00017.wav', 'pop.00016.wav', 'pop.00002.wav']\n"
     ]
    }
   ],
   "source": [
    "train_audio_path = '/Users/jproza/Downloads/genres'\n",
    "labels = ['rock','blues','metal','pop']\n",
    "all_wave = []\n",
    "all_label = []\n",
    "for label in labels:\n",
    "    print(label)\n",
    "    waves = [f for f in os.listdir(train_audio_path + '/'+ label) if f.endswith('.wav')]\n",
    "    print (waves)\n",
    "    for wav in waves:\n",
    "        samples, sample_rate = librosa.load(train_audio_path + '/' + label + '/' + wav, sr = 44100)\n",
    "        samples = librosa.resample(samples, sample_rate, 44100)\n",
    "        #if(len(samples)== 8000) : \n",
    "        all_wave.append(samples)\n",
    "        all_label.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the output labels to integer encoded:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, convert the integer encoded labels to a one-hot vector since it is a multi-classification problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400,)\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "['rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'rock', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'blues', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop', 'pop']\n"
     ]
    }
   ],
   "source": [
    "#one hot encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y=le.fit_transform(all_label)\n",
    "print(y.shape)\n",
    "classes= list(le.classes_)\n",
    "#print(classes)\n",
    "print(y)\n",
    "print(all_label)\n",
    "#print(np.array(all_wave))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape the 2D array to 3D since the input to the conv1d must be a 3D array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400,)\n"
     ]
    }
   ],
   "source": [
    "all_wave = np.array(all_wave)\n",
    "#print(y.shape)\n",
    "print(all_wave.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split into train and validation set**\n",
    "\n",
    "Next, we will train the model on 80% of the data and validate on the remaining 20%:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "[array([-0.0560428 , -0.04250243,  0.00845611, ..., -0.01611531,\n",
      "       -0.00319551,  0.00383932], dtype=float32)\n",
      " array([-0.044938  , -0.03814394, -0.00990358, ...,  0.47097152,\n",
      "        0.36727157,  0.17406915], dtype=float32)\n",
      " array([-0.02036892, -0.02598729, -0.02811732, ...,  0.05988553,\n",
      "        0.04257839,  0.01789702], dtype=float32)\n",
      " array([ 0.00769953,  0.00567135,  0.00254763, ..., -0.19400713,\n",
      "       -0.1574004 , -0.07383071], dtype=float32)\n",
      " array([ 0.02549891,  0.04529775,  0.06931784, ..., -0.3466362 ,\n",
      "       -0.28154236, -0.13752323], dtype=float32)\n",
      " array([-0.02425378, -0.02269923, -0.01870139, ..., -0.48590398,\n",
      "       -0.41379452, -0.20945318], dtype=float32)\n",
      " array([ 0.01464829,  0.01487974,  0.00673812, ..., -0.010032  ,\n",
      "        0.00675702,  0.00857976], dtype=float32)\n",
      " array([-0.04013553, -0.03718458, -0.01278998, ..., -0.05977399,\n",
      "       -0.03519344, -0.01333167], dtype=float32)\n",
      " array([-0.16286717, -0.25013393, -0.29045954, ..., -0.4142803 ,\n",
      "       -0.32021394, -0.13879484], dtype=float32)\n",
      " array([0.05615443, 0.05537656, 0.04552334, ..., 0.12170558, 0.08519834,\n",
      "       0.02570955], dtype=float32)\n",
      " array([-0.17246886, -0.19353528, -0.15509415, ..., -0.0438446 ,\n",
      "       -0.08933665, -0.03404184], dtype=float32)\n",
      " array([-0.165171  , -0.22769329, -0.2336079 , ..., -0.07947468,\n",
      "       -0.06764936, -0.0338672 ], dtype=float32)\n",
      " array([0.03140291, 0.04631389, 0.05153481, ..., 0.06248072, 0.05034284,\n",
      "       0.02442241], dtype=float32)\n",
      " array([ 0.03556786,  0.0559371 ,  0.05314639, ..., -0.14870043,\n",
      "       -0.11422709, -0.0564582 ], dtype=float32)\n",
      " array([0.08315897, 0.12008429, 0.11915378, ..., 0.17896079, 0.1499901 ,\n",
      "       0.07504278], dtype=float32)\n",
      " array([ 0.04974283,  0.0522774 ,  0.03758159, ..., -0.14201485,\n",
      "       -0.14382607, -0.08188237], dtype=float32)\n",
      " array([-0.02221992, -0.05035462, -0.09120896, ..., -0.04329539,\n",
      "       -0.05742997, -0.03493288], dtype=float32)\n",
      " array([-0.0029138 ,  0.03381441,  0.08820076, ...,  0.00066076,\n",
      "        0.00654207,  0.0035137 ], dtype=float32)\n",
      " array([0.05484588, 0.08059318, 0.08765586, ..., 0.02807017, 0.01789262,\n",
      "       0.00674679], dtype=float32)\n",
      " array([0.07165761, 0.09477158, 0.09458899, ..., 0.04114199, 0.0563804 ,\n",
      "       0.03501453], dtype=float32)\n",
      " array([0.14327472, 0.20405252, 0.21396247, ..., 0.06078593, 0.04493684,\n",
      "       0.01943593], dtype=float32)\n",
      " array([-0.00776072, -0.00201221,  0.00377307, ...,  0.05771199,\n",
      "        0.06403678,  0.03804085], dtype=float32)\n",
      " array([-0.11172193, -0.13067758, -0.12457215, ..., -0.08259059,\n",
      "       -0.03728694, -0.00995399], dtype=float32)\n",
      " array([0.29017758, 0.3000489 , 0.22253366, ..., 0.4077067 , 0.37388492,\n",
      "       0.19779101], dtype=float32)\n",
      " array([-0.09973272, -0.1417106 , -0.15179093, ...,  0.29849142,\n",
      "        0.250206  ,  0.12397555], dtype=float32)\n",
      " array([ 0.08621492,  0.10091805,  0.08597241, ..., -0.2076003 ,\n",
      "       -0.16450642, -0.0806265 ], dtype=float32)\n",
      " array([-0.04784519, -0.11974587, -0.15922493, ...,  0.23824172,\n",
      "        0.1883857 ,  0.0905233 ], dtype=float32)\n",
      " array([ 0.06541464,  0.09410165,  0.1008251 , ..., -0.05191962,\n",
      "       -0.04248166, -0.02019447], dtype=float32)\n",
      " array([-0.01070442, -0.01261939, -0.01071365, ..., -0.06433211,\n",
      "       -0.02483741, -0.00329975], dtype=float32)\n",
      " array([ 0.00504328,  0.02453799,  0.05554199, ..., -0.00289181,\n",
      "        0.00083084,  0.0016486 ], dtype=float32)\n",
      " array([-0.07350123, -0.05388873, -0.0057707 , ..., -0.06963987,\n",
      "       -0.07340407, -0.042987  ], dtype=float32)\n",
      " array([-0.07849655, -0.03034258,  0.03441769, ..., -0.07212725,\n",
      "       -0.04998508, -0.02135926], dtype=float32)\n",
      " array([-0.16207238, -0.18646725, -0.16457169, ..., -0.00256531,\n",
      "       -0.0020951 , -0.0008608 ], dtype=float32)\n",
      " array([0.01352397, 0.0219736 , 0.02819057, ..., 0.04320917, 0.039486  ,\n",
      "       0.02057999], dtype=float32)\n",
      " array([-0.23609197, -0.32502162, -0.297689  , ...,  0.6731553 ,\n",
      "        0.5894229 ,  0.30052438], dtype=float32)\n",
      " array([0.600696  , 0.65070033, 0.5482799 , ..., 0.4179909 , 0.3998079 ,\n",
      "       0.1590835 ], dtype=float32)\n",
      " array([ 0.45631996,  0.5115245 ,  0.44152346, ..., -0.127149  ,\n",
      "       -0.11629926, -0.05955426], dtype=float32)\n",
      " array([-0.01493044, -0.04028015, -0.06012178, ...,  0.11428181,\n",
      "        0.04502226,  0.00517465], dtype=float32)\n",
      " array([ 0.07187427,  0.09879847,  0.10452142, ...,  0.00999746,\n",
      "       -0.00630497, -0.00549341], dtype=float32)\n",
      " array([ 0.12453053,  0.17998052,  0.18494558, ..., -0.2095607 ,\n",
      "       -0.17834127, -0.08832798], dtype=float32)\n",
      " array([ 0.04251143,  0.06216603,  0.06825475, ..., -0.03442626,\n",
      "       -0.0294167 , -0.01473847], dtype=float32)\n",
      " array([-0.02329968, -0.03214839, -0.03385161, ..., -0.10745965,\n",
      "       -0.08602913, -0.04155591], dtype=float32)\n",
      " array([-0.02494058,  0.02102616,  0.03791188, ..., -0.1801071 ,\n",
      "       -0.16188665, -0.0868326 ], dtype=float32)\n",
      " array([0.00201646, 0.02942071, 0.06144422, ..., 0.3569982 , 0.29941398,\n",
      "       0.14927022], dtype=float32)\n",
      " array([-0.06650799, -0.09622274, -0.08500399, ..., -0.19738896,\n",
      "       -0.17404467, -0.08861604], dtype=float32)\n",
      " array([-0.23458964, -0.29249224, -0.29058015, ..., -0.03426968,\n",
      "       -0.04766483, -0.0322572 ], dtype=float32)\n",
      " array([ 0.03467987,  0.06478556,  0.08460681, ..., -0.16336967,\n",
      "       -0.15393224, -0.0837127 ], dtype=float32)\n",
      " array([0.04388526, 0.0512558 , 0.04650931, ..., 0.49770114, 0.44357568,\n",
      "       0.23118347], dtype=float32)\n",
      " array([0.33850083, 0.28612462, 0.26471138, ..., 0.25472656, 0.40954286,\n",
      "       0.3450173 ], dtype=float32)\n",
      " array([0.06607717, 0.0935365 , 0.09378497, ..., 0.05588482, 0.04118382,\n",
      "       0.01891741], dtype=float32)\n",
      " array([ 0.03481518, -0.00588404, -0.06999657, ..., -0.12215067,\n",
      "       -0.10861857, -0.05800859], dtype=float32)\n",
      " array([0.14663304, 0.17245287, 0.18391013, ..., 0.08675762, 0.07378987,\n",
      "       0.03796822], dtype=float32)\n",
      " array([0.01143263, 0.01846584, 0.0231109 , ..., 0.03249108, 0.02583083,\n",
      "       0.01240058], dtype=float32)\n",
      " array([0.09930705, 0.16277878, 0.1846756 , ..., 0.14044127, 0.12103733,\n",
      "       0.06042523], dtype=float32)\n",
      " array([0.33152285, 0.31570545, 0.16652434, ..., 0.18503866, 0.14772874,\n",
      "       0.0649328 ], dtype=float32)\n",
      " array([0.02123894, 0.02404227, 0.01736123, ..., 0.02451445, 0.02970504,\n",
      "       0.01389648], dtype=float32)\n",
      " array([-0.10696422, -0.14470802, -0.15181385, ..., -0.09772654,\n",
      "       -0.07642432, -0.03637554], dtype=float32)\n",
      " array([0.16346897, 0.18821745, 0.16398816, ..., 0.04471486, 0.06974511,\n",
      "       0.03846161], dtype=float32)\n",
      " array([ 0.2261787 ,  0.2328474 ,  0.14472254, ..., -0.38834718,\n",
      "       -0.34691504, -0.18297926], dtype=float32)\n",
      " array([-0.07819643, -0.12788697, -0.15311542, ...,  0.00934383,\n",
      "        0.01471922,  0.00800671], dtype=float32)\n",
      " array([-0.11156094, -0.17130359, -0.15298644, ..., -0.28919104,\n",
      "       -0.25440165, -0.127583  ], dtype=float32)\n",
      " array([-0.02394943, -0.04029779, -0.05340725, ..., -0.04646909,\n",
      "        0.00619372,  0.01869276], dtype=float32)\n",
      " array([ 0.03679186,  0.04510458,  0.0473648 , ..., -0.06697702,\n",
      "       -0.08874486, -0.05556551], dtype=float32)\n",
      " array([ 0.03193596,  0.03779102,  0.03937174, ..., -0.43348804,\n",
      "       -0.36141282, -0.18251345], dtype=float32)\n",
      " array([0.01095627, 0.01032662, 0.00551747, ..., 0.00121158, 0.00182677,\n",
      "       0.00122051], dtype=float32)\n",
      " array([-0.11360826, -0.12494739, -0.09122777, ..., -0.23732509,\n",
      "       -0.18520847, -0.08674482], dtype=float32)\n",
      " array([-0.28936842, -0.3340642 , -0.2761886 , ..., -0.11960153,\n",
      "       -0.14599928, -0.08618934], dtype=float32)\n",
      " array([-0.03740837, -0.05033035, -0.04757069, ...,  0.03128741,\n",
      "        0.02823296,  0.0142511 ], dtype=float32)\n",
      " array([ 0.12760085,  0.16521344,  0.16148394, ..., -0.24236101,\n",
      "       -0.19178168, -0.09111169], dtype=float32)\n",
      " array([-0.0883332 , -0.091497  , -0.06644554, ...,  0.08898181,\n",
      "        0.07220997,  0.03608233], dtype=float32)\n",
      " array([-0.02660943, -0.03749869, -0.03896438, ..., -0.05521065,\n",
      "       -0.04890401, -0.02504343], dtype=float32)\n",
      " array([ 0.02690001,  0.0110098 , -0.00157333, ...,  0.25309104,\n",
      "        0.2677787 ,  0.1802344 ], dtype=float32)\n",
      " array([-0.09724497, -0.13804404, -0.13664684, ...,  0.06799853,\n",
      "        0.082844  ,  0.05043167], dtype=float32)\n",
      " array([-0.03754494, -0.00114705,  0.05237692, ...,  0.07097073,\n",
      "        0.05268155,  0.02575886], dtype=float32)\n",
      " array([-0.0104787 , -0.01514791, -0.01631247, ...,  0.08968958,\n",
      "        0.07649388,  0.03827901], dtype=float32)\n",
      " array([0.1504813 , 0.1920548 , 0.196797  , ..., 0.14313985, 0.12646946,\n",
      "       0.06671574], dtype=float32)\n",
      " array([-0.19780554, -0.32204738, -0.38598502, ..., -0.00873673,\n",
      "        0.03845474,  0.03303315], dtype=float32)\n",
      " array([-0.01386016, -0.01317173,  0.02879297, ..., -0.1954307 ,\n",
      "       -0.2205887 , -0.13114953], dtype=float32)\n",
      " array([ 0.01652414,  0.00527071, -0.00661818, ..., -0.00401188,\n",
      "        0.00105554, -0.00692551], dtype=float32)\n",
      " array([-0.03865616, -0.05111257, -0.0609524 , ...,  0.04422035,\n",
      "        0.02916978,  0.01222652], dtype=float32)\n",
      " array([ 0.02096319,  0.02764953,  0.02590404, ...,  0.00125598,\n",
      "       -0.00090787, -0.00045314], dtype=float32)\n",
      " array([ 0.00068505,  0.00984076,  0.0269896 , ..., -0.12800486,\n",
      "       -0.07389051, -0.01456515], dtype=float32)\n",
      " array([ 0.00667712,  0.00211461, -0.0055495 , ...,  0.32324395,\n",
      "        0.2791604 ,  0.14017189], dtype=float32)\n",
      " array([ 0.15271114,  0.19790187,  0.1765482 , ..., -0.19986978,\n",
      "       -0.12853055, -0.05435114], dtype=float32)\n",
      " array([-0.00739645, -0.00410906,  0.00380052, ..., -0.03751448,\n",
      "       -0.01253404, -0.00103689], dtype=float32)\n",
      " array([ 0.01028401,  0.03170457,  0.0277201 , ..., -0.32507163,\n",
      "       -0.3035969 , -0.16330323], dtype=float32)\n",
      " array([-0.39849976, -0.4519199 , -0.43063405, ..., -0.14222203,\n",
      "       -0.08201304, -0.03254286], dtype=float32)\n",
      " array([ 0.02915609,  0.03846771,  0.05576619, ..., -0.01186318,\n",
      "       -0.0134365 , -0.00950324], dtype=float32)\n",
      " array([-0.5207394 , -0.7626992 , -0.82003146, ..., -0.03403344,\n",
      "       -0.03178532, -0.01719474], dtype=float32)\n",
      " array([-0.12444741, -0.14026152, -0.1136498 , ..., -0.4289125 ,\n",
      "       -0.41307688, -0.23442377], dtype=float32)\n",
      " array([-0.00013116,  0.00159949,  0.00464843, ..., -0.01566335,\n",
      "       -0.01652433, -0.00950659], dtype=float32)\n",
      " array([ 0.33966845,  0.38811383,  0.33917648, ...,  0.0760963 ,\n",
      "        0.02751103, -0.0079462 ], dtype=float32)\n",
      " array([-0.41829598, -0.49769658, -0.45962125, ...,  0.13199764,\n",
      "        0.11097237,  0.04657216], dtype=float32)\n",
      " array([0.11895991, 0.15765251, 0.15071155, ..., 0.01408182, 0.01021423,\n",
      "       0.00460634], dtype=float32)\n",
      " array([-0.00931162, -0.03263203, -0.05453644, ..., -0.29074016,\n",
      "       -0.20515366, -0.08856916], dtype=float32)\n",
      " array([-0.03793188, -0.05581273, -0.06267312, ...,  0.01492041,\n",
      "        0.00609797,  0.00117469], dtype=float32)\n",
      " array([-0.08145524, -0.08990291, -0.05173914, ..., -0.02469964,\n",
      "        0.11953683,  0.22053382], dtype=float32)\n",
      " array([ 0.00444938, -0.00439215, -0.00028859, ...,  0.06465609,\n",
      "        0.04518154,  0.0207721 ], dtype=float32)\n",
      " array([ 0.06782717,  0.10672306,  0.11903884, ..., -0.2163286 ,\n",
      "       -0.22606859, -0.12753932], dtype=float32)\n",
      " array([-0.19652784, -0.19372343, -0.08515019, ..., -0.02142125,\n",
      "        0.00115707,  0.01952152], dtype=float32)\n",
      " array([-0.11827554, -0.13572524, -0.12200344, ..., -0.42685732,\n",
      "       -0.3310465 , -0.16400135], dtype=float32)\n",
      " array([-0.06095603, -0.07622399, -0.07740349, ..., -0.01192049,\n",
      "       -0.015396  , -0.00894027], dtype=float32)\n",
      " array([-0.02095681, -0.0308051 , -0.0346703 , ...,  0.00014419,\n",
      "       -0.00171402, -0.00154506], dtype=float32)\n",
      " array([-0.27570036, -0.38602513, -0.38763613, ..., -0.08522052,\n",
      "       -0.07185734, -0.03436887], dtype=float32)\n",
      " array([-0.00126885, -0.00101563, -0.00191066, ...,  0.04002982,\n",
      "        0.01679593,  0.00142897], dtype=float32)\n",
      " array([ 0.16083084,  0.19562964,  0.19656362, ..., -0.44863915,\n",
      "       -0.36285535, -0.17661066], dtype=float32)\n",
      " array([-0.04943281, -0.07486673, -0.08626518, ..., -0.13543716,\n",
      "       -0.11190852, -0.05503152], dtype=float32)\n",
      " array([ 0.00895964,  0.0057144 , -0.00539495, ..., -0.02763843,\n",
      "       -0.02576367, -0.01290873], dtype=float32)\n",
      " array([ 0.17465049,  0.14111723,  0.0554411 , ...,  0.00700172,\n",
      "       -0.00081656, -0.00531494], dtype=float32)\n",
      " array([ 0.18229434,  0.19359066,  0.18163931, ..., -0.00020136,\n",
      "        0.01217976,  0.00883046], dtype=float32)\n",
      " array([-0.06795312, -0.13506807, -0.18336327, ..., -0.11048005,\n",
      "       -0.07790574, -0.0334246 ], dtype=float32)\n",
      " array([ 0.09790539,  0.14146076,  0.15240094, ..., -0.07374657,\n",
      "       -0.06256256, -0.03130927], dtype=float32)\n",
      " array([0.30426088, 0.29965702, 0.24385588, ..., 0.3361557 , 0.3427108 ,\n",
      "       0.18883838], dtype=float32)\n",
      " array([ 0.19135612,  0.2717923 ,  0.28523833, ..., -0.1068113 ,\n",
      "       -0.14865203, -0.09305474], dtype=float32)\n",
      " array([-0.04206578, -0.06435047, -0.07196876, ..., -0.07183053,\n",
      "       -0.06953429, -0.03833589], dtype=float32)\n",
      " array([ 0.01932386,  0.02315442,  0.02176775, ..., -0.07426365,\n",
      "       -0.05666182, -0.02739559], dtype=float32)\n",
      " array([-0.3967637 , -0.4842337 , -0.44871062, ..., -0.58528906,\n",
      "       -0.57404643, -0.31513217], dtype=float32)\n",
      " array([ 0.23565307,  0.33895752,  0.3628779 , ..., -0.13055472,\n",
      "       -0.17808929, -0.10833479], dtype=float32)\n",
      " array([ 0.04807491,  0.08437528,  0.11570628, ..., -0.09479696,\n",
      "       -0.07279505, -0.03276085], dtype=float32)\n",
      " array([-0.12937209, -0.15083197, -0.11403694, ...,  0.13051963,\n",
      "        0.10492007,  0.05057399], dtype=float32)\n",
      " array([-0.09746739, -0.1168628 , -0.09093723, ...,  0.0909654 ,\n",
      "        0.06304676,  0.02683807], dtype=float32)\n",
      " array([-0.00337438, -0.00772739, -0.01130546, ...,  0.03004334,\n",
      "        0.02916168,  0.01557405], dtype=float32)\n",
      " array([-0.11333831, -0.13777739, -0.13088256, ..., -0.29205456,\n",
      "       -0.2499424 , -0.12784919], dtype=float32)\n",
      " array([-0.07611581, -0.11712447, -0.13882883, ..., -0.10795709,\n",
      "       -0.0466419 , -0.00325842], dtype=float32)\n",
      " array([ 0.04876709,  0.02376386, -0.02536597, ...,  0.09880127,\n",
      "        0.06417572,  0.02977198], dtype=float32)\n",
      " array([0.10610382, 0.123557  , 0.12084318, ..., 0.17442782, 0.17150903,\n",
      "       0.08191338], dtype=float32)\n",
      " array([-0.05599621, -0.09959748, -0.13665162, ...,  0.00620111,\n",
      "        0.00847821,  0.0054077 ], dtype=float32)\n",
      " array([-0.03376979, -0.03771489, -0.02255221, ...,  0.04641071,\n",
      "        0.01950525,  0.0048314 ], dtype=float32)\n",
      " array([ 0.0219634 ,  0.02934533,  0.02993833, ..., -0.11323542,\n",
      "       -0.1206686 , -0.06652554], dtype=float32)\n",
      " array([0.36035496, 0.5561686 , 0.6514235 , ..., 0.06543478, 0.05578022,\n",
      "       0.02792766], dtype=float32)\n",
      " array([-0.08693509, -0.1039058 , -0.09691031, ...,  0.02878346,\n",
      "        0.01786033,  0.01615444], dtype=float32)\n",
      " array([-0.13767183, -0.20781037, -0.22643308, ...,  0.00224999,\n",
      "       -0.0092717 , -0.00767252], dtype=float32)\n",
      " array([0.07599689, 0.08706328, 0.07728031, ..., 0.00622072, 0.00971462,\n",
      "       0.00720625], dtype=float32)\n",
      " array([-0.23137456, -0.28227967, -0.26891577, ...,  0.12972613,\n",
      "        0.1619686 ,  0.0956385 ], dtype=float32)\n",
      " array([0.07841831, 0.11870368, 0.13689244, ..., 0.00354096, 0.00720818,\n",
      "       0.00459962], dtype=float32)\n",
      " array([ 0.06778486,  0.00907453, -0.02743582, ...,  0.4476211 ,\n",
      "        0.3503215 ,  0.16015433], dtype=float32)\n",
      " array([-0.07850245, -0.13325365, -0.16394825, ..., -0.07725458,\n",
      "       -0.0652102 , -0.03221394], dtype=float32)\n",
      " array([ 0.08057995,  0.01299735, -0.0507967 , ...,  0.1578842 ,\n",
      "        0.1292963 ,  0.06436143], dtype=float32)\n",
      " array([-0.02073448, -0.01487591,  0.01000133, ..., -0.1019076 ,\n",
      "       -0.08205624, -0.03962528], dtype=float32)\n",
      " array([-0.03530895, -0.01441102,  0.01495792, ...,  0.1328697 ,\n",
      "        0.11396299,  0.05911919], dtype=float32)\n",
      " array([0.012963  , 0.04405647, 0.07448143, ..., 0.20974387, 0.1788311 ,\n",
      "       0.08920477], dtype=float32)\n",
      " array([-0.19621047, -0.23135136, -0.19214405, ..., -0.18779396,\n",
      "       -0.17619637, -0.09757148], dtype=float32)\n",
      " array([ 0.04166869,  0.06198214,  0.06824438, ...,  0.03065774,\n",
      "       -0.02783024, -0.02889214], dtype=float32)\n",
      " array([ 0.03546139,  0.05162974,  0.05605055, ..., -0.45952055,\n",
      "       -0.3832665 , -0.18965197], dtype=float32)\n",
      " array([-0.02771415, -0.05500339, -0.08150611, ...,  0.133896  ,\n",
      "        0.10969902,  0.05244091], dtype=float32)\n",
      " array([-0.08183031, -0.08542295, -0.09775289, ...,  0.16353542,\n",
      "        0.15338391,  0.08046026], dtype=float32)\n",
      " array([0.10381384, 0.15076996, 0.15982813, ..., 0.00321525, 0.00278719,\n",
      "       0.00194552], dtype=float32)\n",
      " array([-0.1290508 , -0.1007554 , -0.03577887, ..., -0.3304515 ,\n",
      "       -0.28366736, -0.14656228], dtype=float32)\n",
      " array([-0.09952461, -0.10262437, -0.06746114, ..., -0.07879149,\n",
      "       -0.06185674, -0.03074392], dtype=float32)\n",
      " array([-0.08518057, -0.11243835, -0.12298645, ...,  0.04763702,\n",
      "        0.03988322,  0.02024729], dtype=float32)\n",
      " array([ 0.1685347 ,  0.19413625,  0.17098399, ..., -0.04936467,\n",
      "       -0.05299947, -0.03076315], dtype=float32)\n",
      " array([0.04446871, 0.06959775, 0.09076776, ..., 0.27111647, 0.2321682 ,\n",
      "       0.11565232], dtype=float32)\n",
      " array([-0.03117445, -0.05222608, -0.0645236 , ..., -0.12249166,\n",
      "       -0.10397475, -0.05173266], dtype=float32)\n",
      " array([-0.06040598, -0.08152507, -0.08282236, ..., -0.37198803,\n",
      "       -0.30571127, -0.14850771], dtype=float32)\n",
      " array([-0.01662369, -0.02509614, -0.02771431, ...,  0.14964166,\n",
      "        0.1237315 ,  0.06063028], dtype=float32)\n",
      " array([-0.04089049, -0.03457126, -0.01695571, ..., -0.13063952,\n",
      "       -0.11514756, -0.05992864], dtype=float32)\n",
      " array([ 0.01655859,  0.02674505,  0.03040504, ..., -0.12570782,\n",
      "       -0.09427893, -0.04328581], dtype=float32)\n",
      " array([-0.01635673, -0.00492776,  0.01353032, ..., -0.0220913 ,\n",
      "       -0.00990216, -0.00300378], dtype=float32)\n",
      " array([ 0.03042893, -0.03734314, -0.05827796, ..., -0.18605033,\n",
      "       -0.16529082, -0.07812613], dtype=float32)\n",
      " array([-0.03322262, -0.0491886 , -0.05511636, ...,  0.10946584,\n",
      "        0.12600738,  0.07178792], dtype=float32)\n",
      " array([-0.03050118, -0.03881422, -0.03570944, ..., -0.00057961,\n",
      "       -0.00227951, -0.00153946], dtype=float32)\n",
      " array([-0.04663077, -0.08791483, -0.12084723, ..., -0.22386499,\n",
      "       -0.18883775, -0.09450534], dtype=float32)\n",
      " array([-0.20299138, -0.13502498, -0.07551639, ..., -0.71851015,\n",
      "       -0.3673909 , -0.08506253], dtype=float32)\n",
      " array([ 0.03833749,  0.04528626,  0.04181874, ..., -0.05324396,\n",
      "       -0.04093147, -0.01566882], dtype=float32)\n",
      " array([0.06011461, 0.08356812, 0.08482451, ..., 0.02779082, 0.02684819,\n",
      "       0.01440504], dtype=float32)\n",
      " array([-0.12630397, -0.1541727 , -0.14523204, ...,  0.03578889,\n",
      "        0.02773881,  0.01118832], dtype=float32)\n",
      " array([0.05849099, 0.07294724, 0.06407286, ..., 0.09176493, 0.11153481,\n",
      "       0.06529397], dtype=float32)\n",
      " array([-0.11272117, -0.14084125, -0.1378516 , ..., -0.02692713,\n",
      "       -0.00326086,  0.00285609], dtype=float32)\n",
      " array([ 0.01240185, -0.07377563, -0.0862346 , ...,  0.6926103 ,\n",
      "        0.6226921 ,  0.331678  ], dtype=float32)\n",
      " array([-0.02663133, -0.03522606, -0.02409272, ..., -0.24261531,\n",
      "       -0.24325389, -0.13808048], dtype=float32)\n",
      " array([ 0.05618258,  0.06684372,  0.06196111, ..., -0.6011445 ,\n",
      "       -0.57576567, -0.30785814], dtype=float32)\n",
      " array([ 0.06817272,  0.04281388, -0.00426479, ..., -0.02645919,\n",
      "       -0.08478421, -0.05328294], dtype=float32)\n",
      " array([ 0.12072963,  0.16455401,  0.14665541, ..., -0.16763839,\n",
      "       -0.10983675, -0.04845889], dtype=float32)\n",
      " array([ 0.31364182,  0.3481992 ,  0.291008  , ..., -0.72738975,\n",
      "       -0.3766604 , -0.0266536 ], dtype=float32)\n",
      " array([-0.01436638, -0.02167048, -0.02475325, ..., -0.04956334,\n",
      "       -0.04608414, -0.02424989], dtype=float32)\n",
      " array([ 0.02278876,  0.04011613,  0.05073241, ..., -0.07123466,\n",
      "       -0.05916239, -0.02948539], dtype=float32)\n",
      " array([-0.06679342, -0.07733013, -0.05662121, ..., -0.24174564,\n",
      "       -0.21825777, -0.11177228], dtype=float32)\n",
      " array([-0.09147617, -0.11696861, -0.11758794, ...,  0.14293781,\n",
      "        0.09261137,  0.03936677], dtype=float32)\n",
      " array([0.17038697, 0.24092649, 0.2380437 , ..., 0.07531744, 0.06162379,\n",
      "       0.0293528 ], dtype=float32)\n",
      " array([-0.00039433,  0.00526668,  0.01333806, ...,  0.1210863 ,\n",
      "        0.09006197,  0.04231725], dtype=float32)\n",
      " array([ 0.13837117,  0.07940379, -0.06852546, ...,  0.0529893 ,\n",
      "        0.08689564,  0.05691706], dtype=float32)\n",
      " array([0.01055259, 0.03662182, 0.06516826, ..., 0.04385281, 0.04478298,\n",
      "       0.02567754], dtype=float32)\n",
      " array([ 0.16176413,  0.18241751,  0.15436248, ..., -0.02323442,\n",
      "       -0.01790154, -0.00884655], dtype=float32)\n",
      " array([-0.95831615, -1.0879067 , -0.98461974, ...,  0.28116423,\n",
      "        0.10364489,  0.00178674], dtype=float32)\n",
      " array([0.22186616, 0.2613592 , 0.23945144, ..., 0.22489564, 0.11284929,\n",
      "       0.02427173], dtype=float32)\n",
      " array([0.03595047, 0.04224379, 0.03846287, ..., 0.09765079, 0.11039496,\n",
      "       0.07628313], dtype=float32)\n",
      " array([0.06037945, 0.07068266, 0.06229474, ..., 0.07190362, 0.05580939,\n",
      "       0.02568515], dtype=float32)\n",
      " array([0.20240314, 0.22455679, 0.18030418, ..., 0.02599035, 0.01396851,\n",
      "       0.00430954], dtype=float32)\n",
      " array([-0.09962035, -0.14447477, -0.15569057, ...,  0.03087756,\n",
      "        0.02476496,  0.01163009], dtype=float32)\n",
      " array([-0.18112876, -0.18127637, -0.1193603 , ...,  0.13443229,\n",
      "        0.11662275,  0.05466242], dtype=float32)\n",
      " array([0.03933533, 0.04267101, 0.02232379, ..., 0.02619331, 0.06208537,\n",
      "       0.04362122], dtype=float32)\n",
      " array([ 0.00906245,  0.00220572, -0.00712794, ...,  0.10291958,\n",
      "        0.08449396,  0.00828124], dtype=float32)\n",
      " array([ 0.04457449,  0.06626428,  0.0745532 , ..., -0.08826843,\n",
      "       -0.08084271, -0.04116094], dtype=float32)\n",
      " array([0.2575686 , 0.40559274, 0.48943898, ..., 0.7115719 , 0.53400624,\n",
      "       0.2421955 ], dtype=float32)\n",
      " array([ 0.18108444,  0.26436776,  0.28416514, ..., -0.47086203,\n",
      "       -0.4199038 , -0.21476781], dtype=float32)\n",
      " array([ 0.07855273,  0.10683081,  0.09958515, ..., -0.02046406,\n",
      "       -0.01287854, -0.00444968], dtype=float32)\n",
      " array([0.13098656, 0.13407877, 0.08950249, ..., 0.26758823, 0.24306273,\n",
      "       0.12785737], dtype=float32)\n",
      " array([0.10146693, 0.11570494, 0.09524509, ..., 0.01839534, 0.01711886,\n",
      "       0.00940662], dtype=float32)\n",
      " array([-0.00397779, -0.01053847, -0.01415692, ...,  0.04572851,\n",
      "        0.04278222,  0.02805946], dtype=float32)\n",
      " array([ 0.11098744,  0.14850836,  0.14900972, ..., -0.0971135 ,\n",
      "       -0.07133341, -0.03316176], dtype=float32)]\n",
      "[2 1 1 0 1 2 1 3 0 3 2 0 0 3 3 1 3 1 0 1 3 1 1 2 0 2 3 3 0 0 1 2 3 0 0 2 2\n",
      " 3 3 0 0 3 2 2 3 1 1 2 2 0 1 1 3 3 3 3 0 1 2 3 2 0 1 1 3 3 1 3 1 3 3 2 3 1\n",
      " 0 1 0 1 2 2 3 2 2 0 1 2 2 1 0 2 0 2 2 0 1 0 2 3 2 2 2 2 3 3 2 2 0 3 1 2 3\n",
      " 0 3 3 3 3 2 0 1 0 3 0 3 0 3 1 0 1 1 3 2 0 2 1 0 2 3 2 0 3 3 2 1 0 1 1 1 1\n",
      " 3 1 3 3 3 3 0 1 0 1 2 3 0 0 2 2 0 1 3 1 2 2 2 2 2 2 3 2 3 2 0 3 3 1 2 2 2\n",
      " 2 2 3 0 1 1 2 0 0 0 3 3 3 2 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#print(np.array(all_wave[:,-1]).shape)\n",
    "#print(y.shape)\n",
    "##all_wave = np.stack(y)\n",
    "#all_wave = all_wave.reshape(1000,)\n",
    "#all_wave.shape\n",
    "#y = y.transpose()\n",
    "#all_wave = np.array(all_wave).reshape(-1,1000,1)\n",
    "#print(all_wave.shape)\n",
    "#print(len(classes))\n",
    "c = []\n",
    "for item in y:    \n",
    " c.append(item)\n",
    "\n",
    "print(np.array(c))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_tr, x_val, y_tr, y_val = train_test_split(all_wave,np.array(y),test_size = 0.5,random_state=777,shuffle=True)\n",
    "\n",
    "print(x_tr)\n",
    "#print(np.stack(x_tr,1))\n",
    "print(np.array(y_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Architecture for this problem**\n",
    "\n",
    "We will build the speech-to-text model using conv1d. Conv1d is a convolutional neural network which performs the convolution along only one dimension. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model building**\n",
    "\n",
    "Let us implement the model using Keras functional API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 200, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 188, 8)            112       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 62, 8)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 62, 8)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 52, 16)            1424      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 17, 16)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 17, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 9, 32)             4640      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 3, 32)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               24832     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 200)               51400     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 200)               40200     \n",
      "=================================================================\n",
      "Total params: 122,608\n",
      "Trainable params: 122,608\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Dropout, Flatten, Conv1D, Input, MaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "K.clear_session()\n",
    "\n",
    "inputs = Input(shape=(200 ,1))\n",
    "\n",
    "#First Conv1D layer\n",
    "conv = Conv1D(8,13, padding='valid', activation='relu', strides=1)(inputs)\n",
    "conv = MaxPooling1D(3)(conv)\n",
    "conv = Dropout(0.3)(conv)\n",
    "\n",
    "#Second Conv1D layer\n",
    "conv = Conv1D(16, 11, padding='valid', activation='relu', strides=1)(conv)\n",
    "conv = MaxPooling1D(3)(conv)\n",
    "conv = Dropout(0.3)(conv)\n",
    "\n",
    "#Third Conv1D layer\n",
    "conv = Conv1D(32, 9, padding='valid', activation='relu', strides=1)(conv)\n",
    "conv = MaxPooling1D(3)(conv)\n",
    "conv = Dropout(0.3)(conv)\n",
    "\n",
    "#Fourth Conv1D layer\n",
    "#conv = Conv1D(64, 7, padding='valid', activation='relu', strides=1)(conv)\n",
    "#conv = MaxPooling1D(3)(conv)\n",
    "#conv = Dropout(0.3)(conv)\n",
    "\n",
    "#Flatten layer\n",
    "conv = Flatten()(conv)\n",
    "\n",
    "#Dense Layer 1\n",
    "conv = Dense(256, activation='relu')(conv)\n",
    "conv = Dropout(0.3)(conv)\n",
    "\n",
    "#Dense Layer 2\n",
    "conv = Dense(200, activation='relu')(conv)\n",
    "conv = Dropout(0.3)(conv)\n",
    "\n",
    "outputs = Dense(200, activation='softmax')(conv)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the loss function to be categorical cross-entropy since it is a multi-classification problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Early stopping and model checkpoints are the callbacks to stop training the neural network at the right time and to save the best model after every epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, min_delta=0.0001) \n",
    "mc = ModelCheckpoint('best_model.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Let us train the model on a batch size of 32 and evaluate the performance on the holdout set:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Diagnostic plot**\n",
    "\n",
    "I’m going to lean on visualization again to understand the performance of the model over a period of time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 1 0 1 2 1 3 0 3 2 0 0 3 3 1 3 1 0 1 3 1 1 2 0 2 3 3 0 0 1 2 3 0 0 2 2\n",
      " 3 3 0 0 3 2 2 3 1 1 2 2 0 1 1 3 3 3 3 0 1 2 3 2 0 1 1 3 3 1 3 1 3 3 2 3 1\n",
      " 0 1 0 1 2 2 3 2 2 0 1 2 2 1 0 2 0 2 2 0 1 0 2 3 2 2 2 2 3 3 2 2 0 3 1 2 3\n",
      " 0 3 3 3 3 2 0 1 0 3 0 3 0 3 1 0 1 1 3 2 0 2 1 0 2 3 2 0 3 3 2 1 0 1 1 1 1\n",
      " 3 1 3 3 3 3 0 1 0 1 2 3 0 0 2 2 0 1 3 1 2 2 2 2 2 2 3 2 3 2 0 3 3 1 2 2 2\n",
      " 2 2 3 0 1 1 2 0 0 0 3 3 3 2 0]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all input arrays must have the same shape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-289-35d1cba6fcae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#print(x_tr.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/python36/lib/python3.6/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out)\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'all input arrays must have the same shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0mresult_ndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all input arrays must have the same shape"
     ]
    }
   ],
   "source": [
    "#print(np.array(y_tr))\n",
    "#print(y_tr.shape)\n",
    "#print(x_val.shape)\n",
    "#print(y_val.shape)\n",
    "\n",
    "#print(model.summary())\n",
    "#print(x_tr)\n",
    "#x_tr = np.expand_dims(x_tr, axis=1)\n",
    "#y_tr = np.expand_dims(y_tr, axis=1)\n",
    "\n",
    "\n",
    "#print(x_tr.shape)\n",
    "#y_tr = np.expand_dims(y_tr, 0)\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(np.array(data.iloc[:, :-1], dtype = float))\n",
    "X = np.stack(y)\n",
    "history=model.fit(np.array(np.reshape(x_tr,[-1,200,1])),np.array(np.reshape(y_tr,[-1,200])) ,epochs=100,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dir = '/Users/jproza/Downloads/genres'\n",
    "if not os.path.exists(target_dir):\n",
    "  os.mkdir(target_dir)\n",
    "model.save('/Users/jproza/Downloads/genres/modelo.h5')\n",
    "model.save_weights('/Users/jproza/Downloads/genres/pesos.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading the best model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model=load_model('/Users/jproza/Downloads/genres/modelo.h5')\n",
    "model.load_weights('/Users/jproza/Downloads/genres/pesos.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict2(audio):\n",
    "  audio=np.array(audio)\n",
    "  audio= np.expand_dims(audio, axis=1)\n",
    "  audio=np.stack(y)\n",
    "  print(audio.shape)\n",
    "  array = model.predict([(audio)])\n",
    "  result = array[0]\n",
    "  answer = np.argmax(result)\n",
    "  print(classes[result(answer)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the function that predicts text for the given audio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(audio):\n",
    "    audio=np.array(audio)\n",
    "    audio=np.stack(y)\n",
    "    prob=model.predict(audio.reshape([1323588, 1]))\n",
    "    index=np.argmax(prob[0])\n",
    "    print (index);\n",
    "    return classes[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction time! Make predictions on the validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 44100\n",
    "samples, sample_rate = librosa.load('/Users/jproza/Enjoy the Silence/blues.00001.wav', sr = 44100)\n",
    "samples = librosa.resample(samples, sr,(sr))\n",
    "#samples = librosa.resample(samples, sr, 8000)\n",
    "#samples=samples.ravel()\n",
    "ipd.Audio(samples,rate=(sr))\n",
    "#print(\"Audio:\",classes[np.argmax(y_val[index])])\n",
    "#ipd.Audio(samples, rate=sr/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Text:\",predict2(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
